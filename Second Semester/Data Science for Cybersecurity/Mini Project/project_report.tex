% This is a Basic Assignment Paper but with like Code and stuff allowed in it, there is also url, hyperlinks from contents included. 

\documentclass[openany]{report}
% Preamble

\usepackage[ruled,vlined]{algorithm2e}
\usepackage[margin=1in]{geometry}
\usepackage{amsfonts, amsmath, amssymb}
\usepackage{fancyhdr, float, graphicx}
\usepackage[utf8]{inputenc} % Required for inputting international characters
\usepackage[T1]{fontenc} % Output font encoding for international characters
% \usepackage{fouriernc} % Use the New Century Schoolbook font
\usepackage[nottoc, notlot, notlof]{tocbibind}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{blindtext}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    filecolor=magenta,      
    urlcolor=blue,
    pdfpagemode=FullScreen,
    }

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

% Header and Footer
\pagestyle{fancy}
\fancyhead{}
\fancyfoot{}
\fancyhead[L]{\textit{\Large{Data Science For Cybersecurity and Forensics - 3nd Year B. Tech}}}
\fancyhead[R]{\textit{Krishnaraj T}}
\fancyfoot[C]{\thepage}
\renewcommand{\footrulewidth}{1pt}

% Other Doc Editing
% \parindent 0ex
%\renewcommand{\baselinestretch}{1.5}

\begin{document}

\begin{titlepage}
    \centering

    %---------------------------NAMES-------------------------------

    \huge\textsc{
        Dr. Vishwanath Karad MIT World Peace University, Pune
    }\\

    \vspace{0.75\baselineskip} % space after Uni Name

    \LARGE{
        Data Science for Cybersecurity\\
        Third Year B. Tech, Semester 6\\
    }

    \vfill % space after Sub Name

    %--------------------------TITLE-------------------------------

    \rule{\textwidth}{1.6pt}\vspace*{-\baselineskip}\vspace*{2pt}
    \rule{\textwidth}{0.6pt}
    \vspace{0.75\baselineskip} % Whitespace above the title



    \huge{\textsc{
            PC Usage Analyzer
        }} \\



    \vspace{0.5\baselineskip} % Whitespace below the title
    \rule{\textwidth}{0.6pt}\vspace*{-\baselineskip}\vspace*{2.8pt}
    \rule{\textwidth}{1.6pt}

    \vspace{1\baselineskip} % Whitespace after the title block

    %--------------------------SUBTITLE --------------------------	

    \LARGE\textsc{
        Mini Project Report
    } % Subtitle or further description

    %--------------------------AUTHOR-------------------------------

    \vspace{0.5\baselineskip} % Whitespace below the editor list
    Under the Guidance of\\
    \Large{
        \textbf{Dr. Sunita Warjri}
    }
    \vfill

    Prepared By
    \vspace{0.5\baselineskip} % Whitespace before the editors

    \Large{
        Krishnaraj Thadesar, PA10, 1032210888\\
    }
    \vspace{0.5\baselineskip} % Whitespace before the editors
    \LARGE{
        Department of School of Computer Engineering and Technology\\
        Maharashtra, India.\\
        2023-2024\\
    }
    % \vspace{0.5\baselineskip} % Whitespace below the editor list
    \today

\end{titlepage}


\tableofcontents
\thispagestyle{empty}
% \frontmatter
\clearpage

\chapter*{Acknowledgment}
\thispagestyle{empty}

I would like to express my deepest appreciation to all those who provided me the possibility to complete this report. A special gratitude I give to our mentor, Prof. Sunita Warjri, whose contribution in stimulating suggestions and encouragement, helped me to coordinate my project especially in writing this report.\\

Furthermore, I would also like to acknowledge with much appreciation the crucial role of the staff of MIT WPU, who gave the permission to use all required equipment and the necessary materials to complete the task. A special thanks goes to my team mates,who helped me enormously to assemble the parts and gave suggestion about the task of using the techniques of measurements.\\

I have to appreciate the guidance given by other supervisor as well as the panels especially in our project presentation that has improved our presentation skills thanks to their comment and advices.\\

I would also like to thank my parents for their wise counsel and sympathetic ear. You are always there for me. Finally, I wish to thank my friends for their support and encouragement throughout my study.



\section*{Name of Student}
\begin{enumerate}
    \item Krishnaraj Thadesar, PA10, 1032210888
\end{enumerate}

\thispagestyle{empty}
\clearpage

\chapter*{Abstract}
We spend a lot of time on our computers, and it can be interesting to see how we use them. This project aims to analyze the usage of a computer by monitoring the applications used, the time spent on each application, and the frequency of usage. The project will involve developing a tool that can track the user's activities on the computer and generate reports based on the data collected. The tool will provide insights into the user's behavior and help identify patterns in computer usage. The project will also explore the privacy implications of monitoring computer usage and discuss ways to protect user data. \\

The project will be implemented using Python and will involve developing scripts to capture and analyze computer usage data. The project will provide a valuable resource for users to understand their computer usage patterns and make informed decisions about their digital habits.\\


For ease of use, Django will be used to create a web interface for the tool, allowing users to view their computer usage data and generate reports. The project will also explore the ethical considerations of monitoring computer usage and discuss the implications of collecting and analyzing user data.\\


This project was intented as a mini project for the Data Science for Cybersecurity and Forensics course at Dr. Vishwanath Karad MIT World Peace University, Pune. The project aims to provide a practical application of data science techniques in the field of cybersecurity and forensics and to explore the potential of monitoring computer usage as a tool for improving digital habits and privacy awareness. But its root and inspiration was from having played a lot of games, and realizing that an analysis of the time spent on the computer could be interesting.

\section{Keywords}
Computer Usage, Monitoring, Analysis, Python, Privacy, Data Collection, Insights, Patterns, Digital Habits.

\thispagestyle{empty}
\clearpage

\listoffigures
\clearpage
\setcounter{page}{1}

\chapter{Introduction}
We spend a siginificant amount of time on our Computers and Laptops everyday, and it can be interesting to see how we use them. This project aims to analyze the usage of a computer by monitoring the applications used, the time spent on each application, and the frequency of usage. The project will involve developing a tool that can track the user's activities on the computer and generate reports based on the data collected. The tool will provide insights into the user's behavior and help identify patterns in computer usage. The project will also explore the privacy implications of monitoring computer usage and discuss ways to protect user data.\\

The project will be implemented using Python and will involve developing scripts to capture and analyze computer usage data. The project will provide a valuable resource for users to understand their computer usage patterns and make informed decisions about their digital habits.\\

\section{Problem Statement}
To learn and analyze how much time is spent by a user on each application of the computer. The tool should provide insights into the user's behavior and help identify patterns in computer usage. The project will also explore the privacy implications of monitoring computer usage and discuss ways to protect user data.\\

\section{Need of the Project}

Just like on Android phones, where we have in built apps like Digital Wellbeing, which gives us insights on how we use our phones, this project aims to provide a similar tool for computers, which doesnt exist by default on Windows systems, and is not available as a free tool either.\\

So the motivation behind this project is to provide a tool that can help users understand their computer usage patterns and make informed decisions about their digital habits. The tool will provide insights into the user's behavior and help identify patterns in computer usage.

\chapter{Literature Survey}
Here we explore tools that are available in the market that provide similar functionality to the one we are trying to build.\\

\subsection{RescueTime}
RescueTime is a time-tracking application that helps you track your activity while working on your computer. After you install and activate RescueTime on your system, you have to start the focus time manually. After that, it starts tracking your time and activities on your system. The time you spent on each app or software is recorded in RescueTime. Moreover, it also keeps a record of the time you spent on different websites in your web browser. You can view all these activities on the RescueTime dashboard. It also generates daily, weekly, monthly, and yearly reports. The report generated by RescueTime will tell you how much time you have spent on different applications and websites so that you can increase your productivity.
\begin{enumerate}
    \item Website
          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{rescuetime.jpg}
              \caption{Rescue Time Website}
          \end{figure}

    \item \textbf{Cost: Only a 14 Day Free trail, Paid after that from 500 Rs per month.}\\

    \item \textbf{Feature Set}
          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{rescuetime featureset.jpg}
              \caption{Rescue Time Feature Set Comparison}
          \end{figure}
\end{enumerate}

\subsection{Toggl}
Toggl Track is a popular time tracking app that is available on a variety of platforms, including Windows, macOS, Android, iOS, and Linux. Toggl Track offers features like manual and automatic time tracking, project management, and reporting.

\begin{enumerate}
    \item Website: \url{https://toggl.com/}\\
          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{toggl.jpg}
              \caption{Toggl Website}
          \end{figure}

    \item \textbf{Cost: Free for Basic, Varying Levels of Subscription Fee, from 750 Rs. Does not Track Ongoing Software}\\

          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{toggl pricing.jpg}
              \caption{Pricing for Toggl}
          \end{figure}
    \item \textbf{Feature Set}
          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{toggl featureset.jpg}
              \caption{Toggl Feature Set Comparison}
          \end{figure}
\end{enumerate}

\subsection{Time Doctor}
Time Doctor is a time tracking and productivity management software that is designed to help businesses and individuals manage their time more effectively. Time Doctor offers features like time tracking, project management, and reporting. Time Doctor is available on a variety of platforms, including Windows, macOS, Android, iOS, and Linux.

\begin{enumerate}
    \item Website: \url{https://www.timedoctor.com/}\\
          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{time doctor.jpg}
              \caption{Time Doctor Website}
          \end{figure}

    \item \textbf{Cost: Free for Basic, Varying Levels of Subscription Fee, from 750 Rs. Does not Track Ongoing Software}

          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{time doctor pricing.jpg}
              \caption{Time Doctor Pricing}
          \end{figure}

    \item \textbf{Feature Set}
          \begin{figure}[H]
              \centering
              \includegraphics[width=.95\textwidth]{time doctor features.jpg}
              \caption{Time Doctor Feature Set Comparison}
          \end{figure}

\end{enumerate}

There are other Solutions like:
\begin{enumerate}
    \item Clockify: Matches feature set that we need, but not reliable in Free Tier. Limited Functinality.
    \item WorkingHours: Free, but you have to manually enter work type. Not automatic.
\end{enumerate}

\chapter{Algorithms and Implementations}


\section{Algorithms}
In building the project, we had to use several different smaller general code algorithms to make the project work, but we will highlight some of the main algorithms used in the project.\\


\subsection{Multinomial Naive Bayes Classifier}

\begin{algorithm}[H]
    \SetAlgoLined
    \KwIn{Training data consisting of process names and their corresponding categories}
    \KwOut{Trained Naive Bayes classifier}
    \BlankLine

    \If{model file exists}{
        Load the pre-trained model from the file\;
        \Return\;
    }

    \BlankLine
    Initialize an empty dictionary to store training data: \textit{training\_data\_dict}\;
    \ForEach{category in training data}{
        \ForEach{process name in the category}{
            Append the process name to \textit{training\_data\_dict["Process Name"]} and its category to \textit{training\_data\_dict["Category"]}\;
        }
    }

    \BlankLine
    Create a DataFrame (\textit{training\_data\_df}) from the \textit{training\_data\_dict}\;

    \BlankLine
    Create a pipeline (\textit{text\_clf}) consisting of the following steps:
    \begin{itemize}
        \item CountVectorizer: Convert a collection of text documents into a matrix of token counts.
        \item TfidfTransformer: Transform a count matrix to a normalized term-frequency or term-frequency times inverse document-frequency representation.
        \item MultinomialNB: Multinomial Naive Bayes classifier.
    \end{itemize}

    \BlankLine
    Train the Naive Bayes classifier (\textit{text\_clf}) using the process names (\textit{training\_data\_df["Process Name"]}) as features and their corresponding categories (\textit{training\_data\_df["Category"]}) as labels\;

    \BlankLine
    Save the trained model (\textit{text\_clf}) to a file named \textit{model.pkl}\;

    \BlankLine
    \Return{The trained Naive Bayes classifier (\textit{text\_clf})}
    \BlankLine

    \caption{Training the Naive Bayes Classifier}
\end{algorithm}

\subsection{Basic Data Collection}
\begin{enumerate}
    \item \textbf{Purpose:} To collect data on the user's computer usage, including the applications used, the time spent on each application, and the frequency of usage.
    \item \textbf{Implementation:}
          \begin{enumerate}
              \item Get the current active window process ID from win32 api in python.
              \item Using the Process ID, get the process name, and the Window Title. Also get the RAM occupied by the process.
              \item Store this data in a pandas dataframe that we initalized during starting of the app.
              \item Keep track of how many seconds this was going on, in each second, update the last record of the dataframe.
              \item If a new app doesnt match the last record in the dataframe, then append another row in the dataframe, with new app details. This could be an app that was recorded previously.
              \item This way each app navigated during the recorded time is kept track of.
          \end{enumerate}
\end{enumerate}

\subsection{Get Categories for This Week}

\begin{algorithm}[H]
    \SetAlgoLined
    \KwIn{None}
    \KwOut{Dictionary of category percentages based on process names}
    \BlankLine

    Train the Naive Bayes classifier using the \textit{train\_model} method\;

    Get today's date (\textit{today})\;
    Get the date 7 days ago (\textit{seven\_days\_ago})\;
    Retrieve the dataframe (\textit{current\_timeframe}) for the current timeframe from the database, including entries between \textit{seven\_days\_ago} and \textit{today}\;

    Load the trained model (\textit{text\_clf}) from the file \textit{model.pkl}\;

    Predict the categories of the process names in \textit{current\_timeframe} using the loaded model (\textit{text\_clf})\;

    Initialize an empty dictionary (\textit{categories}) to store the counts of predicted categories\;

    \ForEach{predicted category}{
        Increment the count of the category in the \textit{categories} dictionary\;
    }

    Calculate the percentage of each category based on the total count\;

    \Return{Dictionary of category percentages (\textit{categories})}
    \BlankLine

    \caption{Get Categories for This Week}
\end{algorithm}

\subsection{Get Least Used Apps of All Time}

\begin{algorithm}[H]
    \SetAlgoLined
    \KwIn{None}
    \KwOut{Dictionary of least used apps and their respective durations}
    \BlankLine

    Initialize an empty dictionary (\textit{least\_used}) to store process names and their summed durations\;

    Iterate over each entry in the database (\textit{self.db})\;
    \Indp
    If the process name is already in \textit{least\_used}, add the duration to its existing value\;
    Otherwise, add a new entry to \textit{least\_used} with the process name and its duration\;
    \Indm

    Convert the dictionary to a DataFrame (\textit{least\_used\_df})\;

    Sort the DataFrame by duration in ascending order\;

    Get the top 10 least used apps from the sorted DataFrame\;

    Convert the DataFrame to a dictionary and return it\;
    \BlankLine

    \caption{Get Least Used Apps of All Time}
\end{algorithm}

\subsection{Get Active Hours of All Time}

\begin{algorithm}[H]
    \SetAlgoLined
    \KwIn{None}
    \KwOut{Dictionary of active hours and their respective durations}
    \BlankLine

    Initialize an empty dictionary (\textit{active\_hours}) to store hours and their summed durations\;

    Iterate over each entry in the database (\textit{self.db})\;
    \Indp
    Extract the hour from the start time of the entry\;
    Add the duration to the respective hour in \textit{active\_hours}\;
    \Indm

    Convert the dictionary to a DataFrame (\textit{active\_hours\_df})\;

    Sort the DataFrame by hour\;

    Convert the DataFrame to a dictionary and return it\;
    \BlankLine

    \caption{Get Active Hours of All Time}
\end{algorithm}

\subsection{Get Weekly Analytics}

\begin{algorithm}[H]
    \SetAlgoLined
    \KwIn{None}
    \KwOut{Dictionary of days and their respective durations for the past week}
    \BlankLine

    Initialize an empty dictionary (\textit{weekly\_analytics}) to store days and their summed durations\;

    Get today's date (\textit{today}) and the date 7 days ago (\textit{seven\_days\_ago})\;

    Iterate over each entry in the database (\textit{self.db})\;
    \Indp
    Extract the date from the start time of the entry\;
    If the date falls within the past week, add the duration to the respective day in \textit{weekly\_analytics}\;
    \Indm

    Convert the dictionary to a DataFrame (\textit{weekly\_analytics\_df})\;

    Sort the DataFrame by day\;

    Convert the DataFrame to a dictionary and return it\;
    \BlankLine

    \caption{Get Weekly Analytics}
\end{algorithm}

\subsection{Get Top Apps of All Time}

\begin{algorithm}[H]
    \SetAlgoLined
    \KwIn{None}
    \KwOut{Dictionary of top apps and their respective durations}
    \BlankLine

    Initialize an empty dictionary (\textit{top\_apps}) to store process names and their summed durations\;

    Iterate over each entry in the database (\textit{self.db})\;
    \Indp
    If the process name is already in \textit{top\_apps}, add the duration to its existing value\;
    Otherwise, add a new entry to \textit{top\_apps} with the process name and its duration\;
    \Indm

    Convert the dictionary to a DataFrame (\textit{top\_apps\_df})\;

    Sort the DataFrame by duration in descending order\;

    Get the top 10 apps from the sorted DataFrame\;

    Convert the DataFrame to a dictionary and return it\;
    \BlankLine

    \caption{Get Top Apps of All Time}
\end{algorithm}


\section{Implementation}
Here are Some code snippets showing how the project was implemented.\\

\subsection{Database Management}

\begin{lstlisting}[language=Python, caption=Database Initialization]
def init_db(self):
    """
    Initializes the database. Reads the csv file named data.csv
    """
    self.db = pd.DataFrame(
        columns=[
            "Title",
            "Process Name",
            "Current Memory Usage",
            "Start Time",
            "Registered End Time",
            "Duration",
        ]
    )

    # check if the data directory exists
    if not os.path.exists(self.data_directory):
        os.makedirs(self.data_directory)
    print("data directory", self.data_directory)

    # try to get data
    try:
        # if the csv file exists, import it to self.db
        if os.path.exists(os.path.join(self.data_directory, "data.csv")):
            with open(os.path.join(self.data_directory, "data.csv"), "r") as f:
                if (
                    os.stat(os.path.join(self.data_directory, "data.csv")).st_size
                    == 0
                ):
                    print("File is empty")
                    print("no data to import, starting fresh")
                    return
            try:
                self.db = pd.read_csv(
                    os.path.join(self.data_directory, "data.csv"),
                    dtype={
                        "Title": str,
                        "Process Name": str,
                        "Current Memory Usage": float,
                        "Start Time": str,
                        "Registered End Time": str,
                        "Duration": str,
                    },
                )
            except Exception as e:
                print(e)
                print("could not read csv due to some issues")

            print("imported data")

            try:
                # find sum of duration
                self.db["Duration"] = pd.to_timedelta(self.db["Duration"])
                print("total duration", self.db["Duration"].sum())
            except Exception as e:
                print(e)
                print("could not convert duration to timedelta")
        else:
            print("no data to import, starting fresh")

    except Exception as e:
        print(e)
        print("could not read csv due to some issues")

\end{lstlisting}

\subsection{Main Application Logic}

\begin{lstlisting}[language=Python, caption=Main Application Logic]
def run(self):
print("running main run function")
"""
Runs the application. This runs every thread_interval_s seconds from the thread.
"""

# Get the active window
active_window = self.get_active_window()
if self.idle_detection:
    if self.cursor_position == pag.position():
        self.cursor_counter += 1
    else:
        self.cursor_position = pag.position()
        self.cursor_counter = 0
    if self.cursor_counter > 300:
        active_window = "idle"
        # change the previous entries summing up to 300 seconds to "idle"
        self.fix_idle()

# get the active process
active_process = self.get_active_process()
active_process_name = active_process.name()

# get the memory usage of the active process
active_process_memory = self.get_active_process_memory(active_process)

# check if the last entry in the db is the same as the current active window
if len(self.db) > 0:
    if self.db.iloc[-1]["Title"] == active_window:
        # just update the end time, duration and break
        self.db.at[len(self.db) - 1, "Registered End Time"] = (
            datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        )
        self.db.at[len(self.db) - 1, "Duration"] = datetime.timedelta(
            seconds=self.db.at[len(self.db) - 1, "Duration"].total_seconds()
            + self.thread_interval_ms / 1000
        )
    else:
        new_row = [
            active_window,
            active_process_name,
            active_process_memory,
            datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            pd.Timedelta(seconds=self.thread_interval_ms / 1000),
        ]

        # add next row to the dataframe
        self.db.loc[len(self.db)] = new_row
        # print("self", self.db)

else:
    new_row = [
        active_window,
        active_process_name,
        active_process_memory,
        datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        pd.Timedelta(seconds=self.thread_interval_ms / 1000),
    ]

    # add next row to the dataframe
    self.db.loc[len(self.db)] = new_row

# if len of db is a multiple of 500, autosave
if (len(self.db)) % 500 == 0 and len(self.db) != 0:
    print("Autosaving after 500 records.")
    self.export_raw()
    if len(self.db) == 20000:
        print("Maximum records reached. Will start fresh.")
        # export raw, but with a different name
        self.export_raw(
            new_name=True,
            name=datetime.datetime.now().strftime("%Y-%m-%d %H-%M-%S"),
        )
        # start fresh
        self.start_fresh()
\end{lstlisting}

\subsection{Model Training}

\begin{lstlisting}[language=Python, caption=Model Training]
def train_model(self):
# train a naive bayes classifier to predict the category of the app based on the process name
# if a modle.pkl file exists here, load it and return
if os.path.exists(os.path.join(self.data_directory, "model.pkl")):
    print("model exists, loading it")
    return

# make a dataframe from the training data
training_data_dict = {"Process Name": [], "Category": []}
for key in training_data.keys():
    for value in training_data[key]:
        training_data_dict["Process Name"].append(value)
        training_data_dict["Category"].append(key)

training_data_df = pd.DataFrame(training_data_dict)

# now we will train the model

# create a pipeline
text_clf = Pipeline(
    [
        ("vect", CountVectorizer()),
        ("tfidf", TfidfTransformer()),
        ("clf", MultinomialNB()),
    ]
)

# train the model
text_clf.fit(training_data_df["Process Name"], training_data_df["Category"])

# save the model
with open(os.path.join(self.data_directory, "model.pkl"), "wb") as f:
    pickle.dump(text_clf, f)

print("model trained and saved")

return text_clf
\end{lstlisting}

\subsection{Model Prediction}

\begin{lstlisting}[language=python, caption=Model Prediction]
self.train_model()
# returns a dictionary percentage of categories. The categories are based on the process names and are tested with the loaded model.

# get todays date
today = datetime.datetime.now().strftime("%Y-%m-%d")

# get the date 7 days ago
seven_days_ago = (
    datetime.datetime.now() - datetime.timedelta(days=7)
).strftime("%Y-%m-%d")

# get the dataframe for the current timeframe
current_timeframe = self.db[
    (self.db["Start Time"].str.split(" ").str[0] <= today)
    & (self.db["Start Time"].str.split(" ").str[0] >= seven_days_ago)
]

text_clf = None
# load the model
with open(os.path.join(self.data_directory, "model.pkl"), "rb") as f:
    text_clf = pickle.load(f)

# now predict using the model.
# predict the categories of the test data
predicted = text_clf.predict(current_timeframe["Title"])

# return the counts by percentage of predicted
categories = {}
for i in range(len(predicted)):
    if predicted[i] in categories:
        categories[predicted[i]] += 1
    else:
        categories[predicted[i]] = 1

return categories
\end{lstlisting}
\section{Platform}
\textbf{Operating System}: Windows 11 Pro x86 \\
\textbf{IDEs or Text Editors Used}: Visual Studio Code\\
\textbf{Compilers or Interpreters}: Python 3.10.1\\

\chapter{Screenshots}
\subsection{Login Page}
The Login page uses the Django Authentication System to authenticate users.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/login.jpg}
    \caption{Login Page}
\end{figure}

\subsection{Signup Page}
The Signup page uses the Django Authentication System to authenticate users, data is stored on a SQLite Database.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/signup.jpg}
    \caption{Signup Page}
\end{figure}

\subsection{Dashboard}
The Dashboard shows the user's computer usage data, like the time spent on each application, the frequency of usage, and the total time spent on the computer.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/dashboard.png}
    \caption{Dashboard}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/dashboard 2.png}
    \caption{Dashboard}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/dashboard 3.png}
    \caption{Dashboard}
\end{figure}

\subsection{Graphs}
The Graphs page shows the user's computer usage data in graphical form, like pie charts and bar graphs.\\

\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/top apps.png}
    \caption{Graph Showing Top Apps}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/hourly.png}
    \caption{Graph Showing Hourly Usage for Today}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/weekly.png}
    \caption{Graph Showing Weekly Usage for this week. }
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/least used.png}
    \caption{Graph Showing Least Used Apps this week. }
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/categories.png}
    \caption{Graph Showing Categories of Apps used this week, made using multinomial Naive Bayes Classifier. }
\end{figure}

\subsection{Profile}
The Profile page shows the user's profile information, and an option to export their data to the Documents Folder.

\begin{figure}[H]
    \centering
    \includegraphics[width=.95\textwidth]{screenshots/profile.png}
    \caption{Profile Page}
\end{figure}

\chapter{Future Prospects}
\begin{enumerate}
    \item \textbf{Encrypt the Database using User Credentials:}
          \begin{itemize}
              \item \textbf{Purpose:} This involves encrypting sensitive data stored in the database using user credentials, such as passwords or other authentication tokens.
              \item \textbf{Implementation:}
                    \begin{itemize}
                        \item Use encryption algorithms such as AES (Advanced Encryption Standard) or RSA (Rivest-Shamir-Adleman) to encrypt the data.
                        \item Generate a key derived from the user's credentials (e.g., password) using a key derivation function (KDF) like PBKDF2 (Password-Based Key Derivation Function 2).
                        \item Encrypt the data using the generated key and store it in the database.
                    \end{itemize}
              \item \textbf{Security Considerations:} Ensure that the encryption keys are securely managed and that decryption is only possible with the user's credentials. Protect against common cryptographic attacks such as brute force and key leakage.
          \end{itemize}

    \item \textbf{Improve Name Display for Each Program:}
          \begin{itemize}
              \item \textbf{Purpose:} This involves enhancing the way program names are displayed within the application or user interface to improve readability and user experience.
              \item \textbf{Implementation:}
                    \begin{itemize}
                        \item Use a consistent naming convention for programs throughout the application.
                        \item Provide clear and descriptive names that accurately represent the functionality of each program.
                        \item Consider organizing programs into categories or groups to make navigation easier for users.
                    \end{itemize}
              \item \textbf{User Interface Considerations:} Ensure that the names are displayed prominently and legibly within the application's user interface, taking into account factors such as font size, color contrast, and layout.
          \end{itemize}

    \item \textbf{Improve Axis Ticks for Graphs:}
          \begin{itemize}
              \item \textbf{Purpose:} This involves enhancing the appearance and readability of axis ticks on graphs to improve data visualization.
              \item \textbf{Implementation:}
                    \begin{itemize}
                        \item Adjust the frequency and spacing of axis ticks to better suit the range and distribution of the data being plotted.
                        \item Use meaningful labels for axis ticks to provide context and clarity to the data.
                        \item Consider formatting axis ticks to include units of measurement, prefixes, or other relevant information.
                    \end{itemize}
          \end{itemize}
\end{enumerate}


\chapter{Conclusion}
In this project, we have developed a tool that can track the user's activities on the computer and generate reports based on the data collected. The tool provides insights into the user's behavior and helps identify patterns in computer usage. The project also explores the privacy implications of monitoring computer usage and discusses ways to protect user data.\\

\textbf{Key Learnings:}
\begin{enumerate}
    \item How to use Python to capture and analyze computer usage data.
    \item How to use Django to create a web interface for the tool.
    \item How to use the multinomial Naive Bayes classifier to categorize applications based on their usage patterns.
    \item How to use the Django Authentication System to authenticate users.
    \item How to use SQLite to store user data.
    \item How to use Matplotlib, Seaborn and Plotly.js to create graphs and charts.
    \item How to use Pandas and NumPy to analyze data.
    \item How to use Scikit-learn to create machine learning models.
\end{enumerate}

\clearpage
\begin{thebibliography}{10}
    \bibitem{phishing101}
    Jakobsson, M., \& Myers, S. (2007). Phishing and Countermeasures: Understanding the Increasing Problem of Electronic Identity Theft. Wiley Publishing.

\end{thebibliography}

\end{document}
